\chapter{Version Control Systems}

The work described in this thesis is about organizing the \emph{software
artifacts} in the Software Heritage graph to make them accessible to
researchers. These artifacts are abstract building blocks that represent the
source code trees, development history and hosting data stored in the archive.
In the next chapter, we will look at how the Software Heritage data model is a
graph built on the relationships between software artifacts. However, to better
grasp this model, it is good to first get a better understanding of how
these objects are captured in the data model of traditional \gls{VCS}.

This chapter describes a generic model for how data is stored in most
\gls{VCS}; it is very close to Git, the most popular of these systems, while
being abstract enough to be independent of any specific implementation.

\section{A simple repository model}

\subsection{Files and directories}

The fundamental elements in a source code repository are, naturally, source
code files. Developers tend to organize their code in different logical units
that are then hierarchized in different levels of directories. At the lowest
granularity, programmers write \emph{functions} that perform a specific task or
computation. A \emph{source code file} is generally a collection of
conceptually related functions, put together as a single logical unit. Source
files that define the behavior of a logically distinct component of a program
are also often logically grouped in the same directory, sometimes called a
\emph{module} or \emph{package}.

\begin{figure}
    \centering
    \begin{subfigure}[b]{.40\textwidth}
        \dirtree{%
            .1 /.
                .2 src.
                    .3 evalexpr.c.
                    .3 parser.
                        .4 ast.c.
                        .4 parser.c.
                        .4 lexer.c.
                .2 tests.
                    .3 eval.c.
                    .3 operands.c.
        }
        \caption{Directory listing.}
        \label{fig:vcs-dir-flat}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{.58\textwidth}
        \centering
        \input{../tikz/figures/dir-tree.tikz}
        \caption{Represented as a tree structure.}%
        \label{fig:vcs-dir-tree}
    \end{subfigure}
    \caption{Example of a directory hierarchy for a code repository.}
    \label{fig:vcs-dir-project}
\end{figure}

The example in \figref{fig:vcs-dir-flat} illustrates a file hierarchy for a
project meant to evaluate simple mathematic expressions. There is always one
root directory containing the entire project, that we represent with a slash.
At the root level, there is a directory containing C source code files, with
some of them organized in a ``parser'' module, and a test directory containing
tests also written in C.

The file hierarchy in this example project can naturally be visualized as a
tree data structure, by representing the directories and the file contents as
the vertices, with their respective names on the edges. The resulting tree is
shown in \figref{fig:vcs-dir-tree}.

\subsection{Revisions}

The concept of \acrlong{VCS} arose from a need to keep track of the
changes happening in the code. This ability is critically important for
software systems, as it allows potentially erroneous changes to be reverted
without having to recall or reconstruct the previous behavior. Furthermore, the
ability to retain institutional knowledge on a codebase by having the
possibility to look up past source code changes is very valuable.

Traditionally, this ``versioning'' could be done by simply copying the software
source tree to a new directory for each new version and keeping around the old
versions as archives of the past state of the code. Generally, creating an
entire new source tree is convoluted, making this manual process tedious and
discouraging small incremental changes. In addition, it also hinders
collaboration between developers, who have to exchange the source files they
are working on and can easily lose track of which version they are developing
on.

However, this basic concept of keeping track of "snapshots" of what the source
tree used to be at different points in time was a key design insight in the
development of most modern \gls{VCS}. They introduce the notion of
\emph{revisions}, which can be conceptualized as a chain of frozen past states
of a source tree that were recorded at various points in time during
development. In some systems, these successive states are known are
\emph{commits}, or sometimes \emph{changesets}, but they all refer to the same
abstract concept.

\begin{figure}
    \centering
    \input{../tikz/figures/rev-chain-example.tikz}
    \caption{Three revisions in the example repository, forming a chain of
    past states of the source tree.}%
    \label{fig:vcs-rev-chain-example}
\end{figure}

\figref{fig:vcs-rev-chain-example} shows three successive states of the source
tree from our example repository, recorded as three different revisions. The
revisions all point to a full copy of the source tree, exactly as it was when its
state was ``frozen''. Each revision also contains a reference to the revision
immediately preceding itself, as a way to keep track of the order in which the
changes were made.\footnote{Note that, somewhat confusingly, this implies that
the arrows are in the opposite direction of time: each revision holds a
reference to its \emph{previous} revision, and thus points towards the
\emph{past}.} By iteratively walking the chain of parents from a given revision,
it is thus possible to visit all the previous states of the repository on which
this revision was based.

Along with its source tree and a reference to its parent, a revision also
typically contains additional metadata: the \emph{date and time} at which it
was created, its \emph{author}, and a \emph{message} describing the changes it
introduced since the last state of the code. Retaining this information
directly in the \gls{VCS} allows to precisely track down when a given change
was made, who authored the change and the rationale given for it. Most systems
expose this information in two ways: as a \emph{log}, where one can look at an
ordered list of all the changes that were made to the source tree (or even a
specific file or sub-directory), and through an \emph{annotate} (or
\emph{blame}) command that shows the revision in which each line of a given
file was modified for the last time.

\subsection{Branching and merging}

A crucial challenge in collaborative software development is that the changes
generally do not happen in a linear fashion. To efficiently share tasks amongst
multiple people, development teams need the ability to work on the codebase
simultaneously, which requires having several versions of the repository in
parallel. In a \gls{VCS}, this is typically achieved through \emph{branching}:
from a single revision, developers can create multiple states of the repository
that can be modified separately and in parallel, which splits the revision
chain.  Generally, developers working on different branches will then attempt
to integrate their respective changes to the main codebase by \emph{merging}
them.  This merging operation combines the split chains back into a single
state, called a \emph{merge revision}.

\begin{figure}
    \centering
    \input{../tikz/figures/rev-branching-merging.tikz}
    \caption{Branching and merging.}%
    \label{fig:vcs-rev-branching-merging}
\end{figure}

\figref{fig:vcs-rev-branching-merging} shows an example of branching and
merging in a revision history.  As can be seen on the merge revision, this
concept extends the simple model introduced above by allowing revisions to
refer to multiple parent revisions as a way to support merging.

When working with multiple revision chains in parallel, it is useful to give
them a name to keep track of their purpose. For that, we can use
\emph{branch} objects, which are simple references to the tip of a revision
chain and which get automatically updated when new revisions are added to it.

In most simple development workflows, developers tend to always keep a main
branch that is long-lived and reflects the current state of the project, and
various kinds of additional ``topic'' branches which contain features that are
currently being worked on in parallel. \figref{fig:vcs-rev-branches} shows an
example of three branches pointing to different revision chains. Note that
since branches are just pointers, there is no obvious notion of a revision
\emph{belonging} to a specific branch, but rather revisions are
\emph{accessible} from one or even several branches.

\begin{figure}[b]
    \centering
    \input{../tikz/figures/rev-branches.tikz}
    \caption{Feature branches keeping track of parallel revision chains.}%
    \label{fig:vcs-rev-branches}
\end{figure}

\subsection{Releases}

Some revisions in the development history are particularly important because
they represent specific milestones in the history of a software. This is often
the case for \emph{software releases}, where the software is distributed to
its users as part of its release cycle, usually being given a numbered version
like ``\texttt{v2.4.3}''.

To be able to refer to these special revisions using mnemonic names like the
software versions themselves, \gls{VCS} allow developers to add named markers,
or \emph{tags}, to some revisions.
While branches already provide a way to refer to a specific revision by a
mnemonic name, they are by nature dynamic and ever-changing, as adding more
revisions to a branch will change the tip of the branch and thus the revision
the branch is pointing to. In contrast, \emph{releases} are static and always
refer to one specific commit.
\figref{fig:vcs-rel-example} shows an example of two releases as first-class
objects in the development history that point to specific revisions.

\begin{figure}
    \centering
    \input{../tikz/figures/rel-example.tikz}
    \caption{Example of a development history with two revisions tagged as
    \emph{releases}, each corresponding to a new version of the software.}%
    \label{fig:vcs-rel-example}
\end{figure}

Similarly to revisions, but unlike branch names which are just hollow named
references, releases can also contain additional metadata: the \emph{date} at
which they were created, the \emph{author} of the release, and a \emph{message}
describing the release.

While releases and branches are typically meant to point to revisions, the data
model of some \gls{VCS} also support the possibility of making them reference
other objects, like files and directories. While this is a generally rare
occurrence, there are some examples of this happening in the wild, and our
data model should accommodate for that possibility.

\section{Artifact deduplication}

The simple repository model we described is general enough to represent the
data stored in the majority of \acrlong{VCS}, both at the level of the files
and directories that constitute the source tree, and at the level of the
development history by capturing the successive states of this source tree over
time.

One immediately apparent issue that arises when trying to implement this model
in a naive way is the sheer amount of \emph{duplication} of identical data
across revisions: creating a new revision for a single line change duplicates
the entire source tree and all the files it contains. This drawback goes
opposite to one of the goal of modern \gls{VCS}, which is to encourage a high
granularity of development history to isolate every logical change in a
separate revision.

However, it is possible to integrate \emph{deduplication} in the model as a way
to reduce its footprint. This section details how we can leverage cryptographic
hash functions to achieve deduplication at the level of single objects and
entire subtrees.

\subsection{Cryptographic hash functions}

The basic primitive used for deduplication in many \gls{VCS} are
\emph{cryptographic hash functions}: mathematical algorithms that can map
arbitrary data into a single fixed-length virtually unique identifier. By
computing the identifier, or \emph{hash}, of each object, it is possible to
check when two objects are identical very quickly by simply comparing their
hashes. Because they have a fixed length, comparing two hashes is an operation
with a time complexity of $O(1)$.

\begin{figure}
    \begin{center}
        \begin{tikzpicture}
            \node [
                shape=rectangle, draw=black, align=left, font=\tiny,
                label={[above]Input text}
            ] (input) at (0, 0)
                {%
                    L'argoumante était églomatique et s'impliquait \\
                    beaucoup plus qu'à l'exparité. Le plus déjà se \\
                    plussissait. Plus qu'à l'exparité s'étrangent et se \\
                    consument les pregmes endiablés de la légume.
            };

            \node [
                shape=ellipse, draw=black, align=left, fill=blue!20,
                label={[above,align=center]Cryptographic \\ hash function}
            ] (hash) at (5.5, 0) {SHA-256};

            \node [
                shape=rectangle, draw=black, align=center, font=\footnotesize,
                label={[above]Result hash}
            ] (output) at (10, 0) {
                % \texttt{7a50e30ada8f09b2}%
                % \texttt{24d348d314de4c09} \\
                % \texttt{ae0ebcb443334442}%
                % \texttt{70cc832ebfc6bc0c}

                \texttt{7a50e30ada8f09b224d34} \\
                \texttt{8d314de4c09ae0ebcb443} \\
                \texttt{33444270cc832ebfc6bc0c}
            };

            \draw[->, >=Stealth] (input) to (hash);
            \draw[->, >=Stealth] (hash) to (output);
        \end{tikzpicture}
    \end{center}
    \caption{A cryptographic hash function converts data of arbitrary size to a
    fixed-length and virtually unique identifier.}%
    \label{fig:}
\end{figure}

Due to the pigeonhole principle, the identifiers cannot be truly unique. If the
resulting hash is 256 bits long, there must be at least one \emph{collision}
in a set of $2^256+1$ elements, that is, at least two elements must have the
same hash. For sufficiently large hash sizes however, assuming the hash
function is resistant to cryptanalytic attacks, it is in practice impossible to
generate a collision as it would require inordinate amounts of time and
computing power, and we can thus be confident that no such collisions exist.
Finding a collision in a 256 bit collision resistant cryptographic hash
function would take more than 2600 times the lifespan of the universe.

In some cases, the hash functions can have weaknesses that are exploited by
cryptanalytic attacks. This is the case of SHA-1, the hash function used by
default as a deduplication method for Git, where a collision was found in
2017~\cite{stevens2017first}.
Various methods can be deployed to reduce susceptibility to these collision
attacks, including detecting and rejecting payloads designed to produce
collisions, or migrating to more secure hash functions. In this thesis, we
always assume that cryptographic hash functions map to a single unique
identifier and discard the possibility of collisions.

\subsection{Deduplicating single files}

Armed with cryptographic hashes, it becomes relatively easy to deduplicate the
identical files that get copied between each revision. We systematically
compute the hash of each file and only store them once. If a new directory
references a file with a hash that has already been stored, instead of storing
the file again, the directory just references the file that is already in the
storage.

\begin{figure}
    \centering
    \input{../tikz/figures/deduplicate-contents.tikz}
    \caption{Deduplication of files with identical hashes. The transparent
    files are detected as duplicate objects, removed and replaced by a pointer
    to the already existing objects (red arrows).}%
    \label{fig:deduplicate-contents}
\end{figure}

\figref{fig:deduplicate-contents} shows an example of deduplication at the file
level, based on the example repository shown in
\figref{fig:vcs-rev-chain-example}. The \gls{VCS} computes the hash of each
file (for simplicity purposes, hashes are represented as single letters). As
more revisions are added to the repository, the multiple states of the source
tree will tend to reference files that have already been stored in the system.
Because the hash of these files will match the hash of the previous files, they
will get deduplicated and only stored once. Here, the file with hash A is
present in three different directories and the files with hashes B, C and D are
present in two different directories, but these directories all reference the
same unique objects.

\subsection{Deduplicating subtrees}
